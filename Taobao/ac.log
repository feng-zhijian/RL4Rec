nohup: 忽略输入
WARNING:tensorflow:From NextItNet_AC.py:194: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From NextItNet_AC.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From NextItNet_AC.py:50: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From NextItNet_AC.py:103: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From NextItNet_AC.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/max/Desktop/Projects/RL4REC/Taobao/NextItNetModules.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/max/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/max/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From NextItNet_AC.py:97: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/max/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From NextItNet_AC.py:201: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From NextItNet_AC.py:204: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-10-29 14:31:54.749626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-10-29 14:31:54.753463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.753573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.665
pciBusID: 0000:01:00.0
2024-10-29 14:31:54.753704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-10-29 14:31:54.754422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-10-29 14:31:54.755196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-10-29 14:31:54.755464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-10-29 14:31:54.756524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-10-29 14:31:54.757219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-10-29 14:31:54.759051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-10-29 14:31:54.759183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.759304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.759357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-10-29 14:31:54.759623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2024-10-29 14:31:54.763912: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2496000000 Hz
2024-10-29 14:31:54.764639: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28e0130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-10-29 14:31:54.764674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-10-29 14:31:54.806582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.806733: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40dab00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-10-29 14:31:54.806763: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2024-10-29 14:31:54.806928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.807039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.665
pciBusID: 0000:01:00.0
2024-10-29 14:31:54.807075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-10-29 14:31:54.807092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-10-29 14:31:54.807107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-10-29 14:31:54.807121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-10-29 14:31:54.807135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-10-29 14:31:54.807149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-10-29 14:31:54.807163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-10-29 14:31:54.807208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.807383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.807491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-10-29 14:31:54.807541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-10-29 14:31:54.807733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-10-29 14:31:54.807747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-10-29 14:31:54.807751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-10-29 14:31:54.807820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.807917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-10-29 14:31:54.807984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20029 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
WARNING:tensorflow:From NextItNet_AC.py:206: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2024-10-29 14:31:56.816504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-10-29 14:31:56.933537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
the loss in 200th batch is: 1.539916
the loss in 400th batch is: 3.119002
the loss in 600th batch is: 1.862051
the loss in 800th batch is: 2.356846
the loss in 1000th batch is: 2.115236
the loss in 1200th batch is: 1.831518
the loss in 1400th batch is: 1.872617
the loss in 1600th batch is: 2.369211
the loss in 1800th batch is: 1.775285
the loss in 2000th batch is: 1.478841
#############################################################
total clicks: 4416 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 5: 0.200000
clicks hr ndcg @ 5 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 10: 0.400000
clicks hr ndcg @ 10 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 15: 0.600000
clicks hr ndcg @ 15 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 20: 0.800000
clicks hr ndcg @ 20 : 0.000000, 0.000000
#############################################################
the loss in 2200th batch is: 1.839304
the loss in 2400th batch is: 2.225168
the loss in 2600th batch is: 1.771290
the loss in 2800th batch is: 1.663831
the loss in 3000th batch is: 1.541981
the loss in 3200th batch is: 1.619215
the loss in 3400th batch is: 1.750479
the loss in 3600th batch is: 1.646592
the loss in 3800th batch is: 1.811321
the loss in 4000th batch is: 1.464579
#############################################################
total clicks: 4416 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 5: 0.400000
clicks hr ndcg @ 5 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 10: 0.400000
clicks hr ndcg @ 10 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 15: 0.600000
clicks hr ndcg @ 15 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 20: 0.800000
clicks hr ndcg @ 20 : 0.000000, 0.000000
#############################################################
the loss in 4200th batch is: 1.701350
the loss in 4400th batch is: 1.908471
the loss in 4600th batch is: 1.776702
the loss in 4800th batch is: 1.611254
the loss in 5000th batch is: 1.460811
the loss in 5200th batch is: 1.538672
the loss in 5400th batch is: 1.617463
the loss in 5600th batch is: 1.522729
the loss in 5800th batch is: 1.437695
the loss in 6000th batch is: 1.581934
#############################################################
total clicks: 4416 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 5: 0.600000
clicks hr ndcg @ 5 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 10: 0.600000
clicks hr ndcg @ 10 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 15: 0.600000
clicks hr ndcg @ 15 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 20: 0.600000
clicks hr ndcg @ 20 : 0.000000, 0.000000
#############################################################
the loss in 6200th batch is: 1.497116
the loss in 6400th batch is: 1.087005
the loss in 6600th batch is: 1.441803
the loss in 6800th batch is: 1.246223
the loss in 7000th batch is: 1.630313
the loss in 7200th batch is: 2.003373
the loss in 7400th batch is: 1.286714
the loss in 7600th batch is: 1.104368
the loss in 7800th batch is: 1.702632
the loss in 8000th batch is: 1.753184
#############################################################
total clicks: 4416 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 5: 0.400000
clicks hr ndcg @ 5 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 10: 0.400000
clicks hr ndcg @ 10 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 15: 0.400000
clicks hr ndcg @ 15 : 0.000000, 0.000000
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cumulative reward @ 20: 0.800000
clicks hr ndcg @ 20 : 0.000000, 0.000000
#############################################################
the loss in 8200th batch is: 1.490078
the loss in 8400th batch is: 1.473386
the loss in 8600th batch is: 1.355718
the loss in 8800th batch is: 1.731659
the loss in 9000th batch is: 1.519069
the loss in 9200th batch is: 1.089402
the loss in 9400th batch is: 1.435113
